{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:35:30.315359Z",
     "start_time": "2020-06-02T15:35:30.293358Z"
    }
   },
   "outputs": [],
   "source": [
    "%run ../initEnviroment.py\n",
    "from plot_data import PlotActivity\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.stats import norm, kurtosis\n",
    "import os\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "from scipy import signal\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from collections import Counter\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:35:31.806489Z",
     "start_time": "2020-06-02T15:35:31.794496Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_test_data(experiment):\n",
    "    \n",
    "    if experiment < 10:\n",
    "        experiment = '0' + str(experiment)\n",
    "    else:\n",
    "        experiment = str(experiment)\n",
    "\n",
    "    for j in os.listdir('../data/RawData/'):\n",
    "\n",
    "        if \"acc_exp\" + experiment in j:\n",
    "            \n",
    "            acc_path = \"../data/RawData/\" + j\n",
    "\n",
    "        elif \"gyro_exp\" + experiment in j:\n",
    "            \n",
    "            gyro_path = \"../data/RawData/\" + j\n",
    "            \n",
    "    acc_df = pd.read_csv(acc_path, sep = \" \", names=['acc_x','acc_y','acc_z'])\n",
    "    gyro_df = pd.read_csv(gyro_path, sep = \" \", names=['gyro_x','gyro_y','gyro_z'])\n",
    "\n",
    "    exp_df = pd.concat([acc_df,gyro_df],1)\n",
    "    exp_df[\"experiment\"] = int(experiment) #keep track of the experiment\n",
    "\n",
    "        \n",
    "    return exp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:35:33.091752Z",
     "start_time": "2020-06-02T15:35:33.080759Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_real_data():\n",
    "    \n",
    "    acc_df = pd.read_csv(\"../data/RealData/Accelerometer.csv\", sep = \",\", \n",
    "                         names=['time','acc_x','acc_y','acc_z'],header=None)\n",
    "    acc_df.drop('time',axis = 1, inplace = True)\n",
    "    acc_df.drop(0,inplace=True)\n",
    "    \n",
    "    \n",
    "    gyro_df = pd.read_csv(\"../data/RealData/Gyroscope.csv\", sep = \",\", \n",
    "                          names=['time','gyro_x','gyro_y','gyro_z'], header = None) \n",
    "    gyro_df.drop('time',axis = 1, inplace = True)\n",
    "    gyro_df.drop(0,inplace=True)\n",
    "    \n",
    "    df = pd.concat([acc_df,gyro_df],1)\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df = df.astype(\"float\")\n",
    "    \n",
    "    return df/9.8070"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:35:34.517935Z",
     "start_time": "2020-06-02T15:35:34.512937Z"
    }
   },
   "outputs": [],
   "source": [
    "#df =  read_real_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:35:35.734239Z",
     "start_time": "2020-06-02T15:35:35.714256Z"
    }
   },
   "outputs": [],
   "source": [
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def filter_acc(df, cutoff=10, fs=50, order=2):\n",
    "    \n",
    "    signals = [\"acc_x\",\"acc_y\",\"acc_z\"]\n",
    "    \n",
    "    new_df = pd.DataFrame(columns=signals)\n",
    "\n",
    "    list_signals = []\n",
    "\n",
    "    for j in signals:\n",
    "\n",
    "        filtered_signal = butter_lowpass_filter(df[j], cutoff=cutoff, fs=fs, order=order)\n",
    "\n",
    "        list_signals.append(filtered_signal)\n",
    "\n",
    "    new_df = pd.concat([new_df, pd.DataFrame(np.array(list_signals).T,columns=signals)])\n",
    "\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def filter_gyro(df, cutoff=10, fs=50, order=2):\n",
    "    \n",
    "    signals = [\"gyro_x\",\"gyro_y\",\"gyro_z\"]\n",
    "    \n",
    "    new_df = pd.DataFrame(columns=signals)\n",
    "    \n",
    "    list_signals = []\n",
    "\n",
    "    for j in signals:\n",
    "\n",
    "        filtered_signal = butter_lowpass_filter(df[j], cutoff=cutoff, fs=fs, order=order)\n",
    "\n",
    "        list_signals.append(filtered_signal)\n",
    "\n",
    "    new_df = pd.concat([new_df, pd.DataFrame(np.array(list_signals).T,columns=signals)])\n",
    "        \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:35:37.047488Z",
     "start_time": "2020-06-02T15:35:37.039492Z"
    }
   },
   "outputs": [],
   "source": [
    "def remake_df(df):\n",
    "    \n",
    "    filtered_df_acc = filter_acc(df,cutoff = 12)\n",
    "    filtered_df_gyro = filter_gyro(df,cutoff= 2)\n",
    "\n",
    "\n",
    "    df = pd.concat([filtered_df_acc.reset_index(drop=True), filtered_df_gyro.reset_index(drop=True)], axis=1)\n",
    "    df.reset_index(inplace = True)\n",
    "    \n",
    "    df.rename(columns={'index': 'sample'},inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create clock df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:35:38.242804Z",
     "start_time": "2020-06-02T15:35:38.235806Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_block_df(df,window_size):\n",
    "    \n",
    "    df['flag'] = np.where(df.index % window_size == 0,1,0)\n",
    "    df[\"block\"] = df['flag'].cumsum()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate data for the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:35:39.511078Z",
     "start_time": "2020-06-02T15:35:39.500085Z"
    }
   },
   "outputs": [],
   "source": [
    "def kurtosis_time(x):\n",
    "\n",
    "    return kurtosis(x, fisher=True)\n",
    "\n",
    "def rms_100(x):\n",
    "\n",
    "    return np.sqrt(np.mean(x**2)) \n",
    "\n",
    "def crest(x):\n",
    "    \n",
    "    return max(abs(x))/np.sqrt(np.mean(x**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:35:40.764361Z",
     "start_time": "2020-06-02T15:35:40.753366Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_aggregated(block_df):\n",
    "    \n",
    "    signals = [\"acc_x\", \"acc_y\", \"acc_z\", \"gyro_x\", \"gyro_y\", \"gyro_z\"]\n",
    "    \n",
    "    samples = {\"sample\": [\"first\",'last']}\n",
    "    functions = {x: [\"sum\", \"mean\", \"mad\",\n",
    "                    \"median\", \"min\", \"max\", \n",
    "                    \"std\", \"var\", \"sem\", \n",
    "                    \"skew\", \"quantile\", \n",
    "                    kurtosis_time, rms_100, \n",
    "                    crest] for x in signals}\n",
    "    \n",
    "\n",
    "    samples.update(functions)\n",
    "    \n",
    "    agg_df = block_df.groupby(\"block\").agg(samples)\n",
    "    \n",
    "    return agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:35:42.060617Z",
     "start_time": "2020-06-02T15:35:42.045630Z"
    }
   },
   "outputs": [],
   "source": [
    "def do_fft(df):\n",
    "    \n",
    "    \"Creat a new df with the frequency spectrum of each blocks\"\n",
    "    \n",
    "    signals = [\"acc_x\",\"acc_y\",\"acc_z\",\"gyro_x\",\"gyro_y\",\"gyro_z\"]\n",
    "    #df.columns = ['index', 'id', 'experiment', 'activity'] + signals + [\"block\"]\n",
    "    \n",
    "    new_df = pd.DataFrame()\n",
    "    \n",
    "    for block in df.block.unique():\n",
    "        \n",
    "        fft_df = df[df[\"block\"] == block]\n",
    "        \n",
    "        list_signals = []\n",
    "        \n",
    "        for j in signals:\n",
    "            \n",
    "            freq, amp = signal.welch(fft_df[j], 50, nperseg=64)\n",
    "            \n",
    "            list_signals.append(amp)\n",
    "            \n",
    "        list_signals.append(np.full(len(freq), block))\n",
    "        \n",
    "        new_df = pd.concat([new_df, pd.DataFrame(np.array(list_signals).T,columns=[x+\"_FFT\" for x in signals]+[\"block\"])])\n",
    "        new_df.dropna(axis=1,inplace=True)\n",
    "        \n",
    "        \n",
    "    #new_df[\"freq\"] = np.tile(x,len(df.block.unique()))\n",
    "    new_df[\"block\"] = new_df[\"block\"].astype('int32')\n",
    "        \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:35:43.257933Z",
     "start_time": "2020-06-02T15:35:43.250938Z"
    }
   },
   "outputs": [],
   "source": [
    "# fft_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:35:44.449251Z",
     "start_time": "2020-06-02T15:35:44.431262Z"
    }
   },
   "outputs": [],
   "source": [
    "def peak_sum_all(x):\n",
    "    \n",
    "    peaks, _ = signal.find_peaks(x, height=0,)\n",
    "    \n",
    "    return sum(peaks)\n",
    "\n",
    "def peak_mean_12(x):\n",
    "    \n",
    "    peaks, hight = signal.find_peaks(x, height=0,)\n",
    "    hight[\"peak_heights\"][::-1].sort()\n",
    "    \n",
    "    if len( hight[\"peak_heights\"])>=12:\n",
    "    \n",
    "        return np.mean(hight[\"peak_heights\"][:12])\n",
    "\n",
    "def peak_mean_8(x):\n",
    "    \n",
    "    peaks, hight = signal.find_peaks(x, height=0,)\n",
    "    hight[\"peak_heights\"][::-1].sort()\n",
    "    \n",
    "    if len( hight[\"peak_heights\"])>=8:\n",
    "    \n",
    "        return np.mean(hight[\"peak_heights\"][:8])\n",
    "\n",
    "def peak_mean_6(x):\n",
    "    \n",
    "    peaks, hight = signal.find_peaks(x, height=0,)\n",
    "    hight[\"peak_heights\"][::-1].sort()\n",
    "    \n",
    "    if len( hight[\"peak_heights\"])>=6:\n",
    "    \n",
    "        return np.mean(hight[\"peak_heights\"][:6])\n",
    "\n",
    "def peak_mean_2(x):\n",
    "    \n",
    "    peaks, hight = signal.find_peaks(x, height=0,)\n",
    "    hight[\"peak_heights\"][::-1].sort()\n",
    "    \n",
    "    if len( hight[\"peak_heights\"])>=2:\n",
    "    \n",
    "        return np.mean(hight[\"peak_heights\"][:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:35:45.619581Z",
     "start_time": "2020-06-02T15:35:45.601590Z"
    }
   },
   "outputs": [],
   "source": [
    "def kurtosis_freq(x):\n",
    "\n",
    "    return kurtosis(x, fisher=True)\n",
    "\n",
    "def rms_10(x):\n",
    "    \n",
    "    y = x[:int(len(x)*0.1)]\n",
    "    \n",
    "    return np.sqrt(np.mean(y*2))\n",
    "def rms_20(x):\n",
    "    \n",
    "    y = x[:int(len(x)*0.20)]\n",
    "    \n",
    "    return np.sqrt(np.mean(y**2))\n",
    "\n",
    "def rms_50(x):\n",
    "    \n",
    "    y = x[:int(len(x)*0.50)]\n",
    "    \n",
    "    return np.sqrt(np.mean(y**2))\n",
    "\n",
    "def rms_80(x):\n",
    "    \n",
    "    y = x[:int(len(x)*0.80)]\n",
    "    \n",
    "    return np.sqrt(np.mean(y**2))\n",
    "\n",
    "def rms_100(x):\n",
    "\n",
    "    return np.sqrt(np.mean(x**2)) \n",
    "\n",
    "def quad_sum(x):\n",
    "    \n",
    "    return np.sum(x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:35:46.813897Z",
     "start_time": "2020-06-02T15:35:46.806902Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_aggregated_freq(fft_df):\n",
    "    \n",
    "    signals = ['acc_x_FFT', 'acc_y_FFT', 'acc_z_FFT', 'gyro_x_FFT', 'gyro_y_FFT','gyro_z_FFT']\n",
    "\n",
    "    fft_agg_df = fft_df.groupby(\"block\").agg({x: [\"sum\", \"mean\", \"mad\",\n",
    "                                                  \"median\", \"min\", \"max\", \n",
    "                                                  \"std\", \"var\", \"sem\", \n",
    "                                                  \"skew\", \"quantile\",\n",
    "                                                  peak_sum_all, kurtosis_freq, peak_mean_2,\n",
    "                                                  peak_mean_6, peak_mean_8, peak_mean_12,\n",
    "                                                  rms_10, rms_20, rms_50,\n",
    "                                                  rms_80, rms_100, quad_sum] for x in signals })\n",
    "    return fft_agg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:35:47.958243Z",
     "start_time": "2020-06-02T15:35:47.949247Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_clf_data(agg_df,fft_agg_df):\n",
    "    \n",
    "    features = agg_df.merge(fft_agg_df,on=\"block\")\n",
    "    clf_data = features.drop([('sample','first'),('sample','last')],axis=1)\n",
    "    \n",
    "    return clf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:35:49.199534Z",
     "start_time": "2020-06-02T15:35:49.190537Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "  \n",
    "    \n",
    "    features_to_drop = []\n",
    "    for i,r in pd.read_csv(\"features_to_drop.txt\",index_col=0).iterrows():\n",
    "        features_to_drop.append(tuple(r))\n",
    "    \n",
    "    df.drop(features_to_drop,axis=1, inplace = True)\n",
    "   \n",
    "    return clf_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:35:50.421834Z",
     "start_time": "2020-06-02T15:35:50.414835Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model(filename):\n",
    "    \n",
    "    # load the model from disk\n",
    "    model = joblib.load(filename)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:35:51.818034Z",
     "start_time": "2020-06-02T15:35:51.812035Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify(df,model):\n",
    "    \n",
    "    labels = model.predict(df)\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:35:53.100301Z",
     "start_time": "2020-06-02T15:35:53.092303Z"
    }
   },
   "outputs": [],
   "source": [
    "def label_original(df, labels, model):\n",
    "    \n",
    "    labels = pd.DataFrame(labels,index=[x for x in range(1,len(labels)+1)], columns=[\"labels\"])\n",
    "    labeled_df = df.merge(labels, how='outer', left_on=\"block\", right_on=labels.index)\n",
    "    \n",
    "    return labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:35:54.246643Z",
     "start_time": "2020-06-02T15:35:54.241647Z"
    }
   },
   "outputs": [],
   "source": [
    "def most_common_label(x):\n",
    "    c = Counter(x)\n",
    "    return c.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:35:55.369004Z",
     "start_time": "2020-06-02T15:35:55.359007Z"
    }
   },
   "outputs": [],
   "source": [
    "def label_agg_df(agg_df,labels):\n",
    "    \n",
    "    labels = pd.DataFrame(labels,index=[x for x in range(1,len(labels)+1)], columns=[\"labels\"])\n",
    "    labeled_agg_df = agg_df[\"sample\"].merge(labels, how='outer', left_on=\"block\", right_on=labels.index)\n",
    "    labeled_agg_df[\"smooth_block\"] = labeled_agg_df[\"labels\"].rolling(5,center=True).apply(most_common_label)\n",
    "    \n",
    "    return labeled_agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:35:56.862146Z",
     "start_time": "2020-06-02T15:35:56.813173Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_activity(labeled_df, labeled_agg_df, experiment = True, experiment_n = 2,\n",
    "                  save = True, save_as = \"../reports/plot.png\"):\n",
    "    \n",
    "    plt.figure()\n",
    "    ax=plt.subplot(2, 1, 1)\n",
    "    ax.plot(np.linspace(0,len(labeled_df[\"acc_x\"]),len(labeled_df[\"acc_x\"])),\n",
    "                        labeled_df[\"acc_x\"], c=\"#003366\")\n",
    "    colors = {0: \"white\", 1:'blue',2:\"orange\",3:'green', 4:'red', 5:'purple', 6:'brown',\n",
    "              7:'pink',8: 'gray', 9:'olive', 10:'cyan', 11:'limegreen',12:'yellow'}\n",
    "    \n",
    "    activity ={0:'No_Activity',\n",
    "               1: 'WALKING',\n",
    "                2: 'WALKING_UPSTAIRS',\n",
    "                3: 'WALKING_DOWNSTAIRS',\n",
    "                4: 'SITTING',\n",
    "                5: 'STANDING',\n",
    "                6: 'LAYING',\n",
    "                7: 'STAND_TO_SIT',\n",
    "                8: 'SIT_TO_STAND',\n",
    "                9: 'SIT_TO_LIE',\n",
    "                10: 'LIE_TO_SIT',\n",
    "                11: 'STAND_TO_LIE',\n",
    "                12: 'LIE_TO_STAND'}\n",
    "\n",
    "    for index,row in labeled_agg_df.iterrows():\n",
    "\n",
    "        start = row['first']\n",
    "        end = row[\"last\"]\n",
    "        c = colors[row['labels']]\n",
    "\n",
    "        rect = plt.Rectangle((start,labeled_df[\"acc_x\"].min()), \n",
    "                             (end-start),\n",
    "                             labeled_df[\"acc_x\"].max()-labeled_df[\"acc_x\"].min(),\n",
    "                             color = c, alpha = 0.4)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    custom_lines = []\n",
    "\n",
    "    for c in colors:\n",
    "\n",
    "        custom_lines.append(Line2D([0], [0], color=colors[c], lw=4, alpha= 0.7))\n",
    "\n",
    "    ax.legend(custom_lines, [activity[x] for x in colors],\n",
    "             loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "              fancybox=True, shadow=True, ncol=5)\n",
    "    \n",
    "    ax.set_xlabel(\"time $[s]$\")\n",
    "    ax.set_ylabel(\"Amplitude\")\n",
    "    ax.set_title(\"Classified Data\")\n",
    "    ax.grid()\n",
    "    \n",
    "    if experiment:\n",
    "        \n",
    "        labeled_agg_df = pd.read_csv('../data/RawData/labels.txt', sep=\" \", header=None)\n",
    "        labeled_agg_df.columns = ['experiment','person','labels','first','last']\n",
    "        labeled_agg_df= labeled_agg_df[labeled_agg_df[\"experiment\"] == experiment_n]\n",
    "        \n",
    "\n",
    "        ax=plt.subplot(2, 1, 2)\n",
    "        ax.plot(np.linspace(0,len(labeled_df[\"acc_x\"]),len(labeled_df[\"acc_x\"])),\n",
    "                            labeled_df[\"acc_x\"], c=\"#003366\");\n",
    "        colors = {0: \"white\", 1:'blue',2:\"orange\",3:'green', 4:'red', 5:'purple', 6:'brown',\n",
    "                  7:'pink',8: 'gray', 9:'olive', 10:'cyan', 11:'limegreen',12:'yellow'}\n",
    "\n",
    "        activity ={0:'No_Activity',\n",
    "                   1: 'WALKING',\n",
    "                    2: 'WALKING_UPSTAIRS',\n",
    "                    3: 'WALKING_DOWNSTAIRS',\n",
    "                    4: 'SITTING',\n",
    "                    5: 'STANDING',\n",
    "                    6: 'LAYING',\n",
    "                    7: 'STAND_TO_SIT',\n",
    "                    8: 'SIT_TO_STAND',\n",
    "                    9: 'SIT_TO_LIE',\n",
    "                    10: 'LIE_TO_SIT',\n",
    "                    11: 'STAND_TO_LIE',\n",
    "                    12: 'LIE_TO_STAND'}\n",
    "\n",
    "        for index,row in labeled_agg_df.iterrows():\n",
    "\n",
    "            start = row['first']\n",
    "            end = row[\"last\"]\n",
    "            c = colors[row['labels']]\n",
    "\n",
    "            rect = plt.Rectangle((start,labeled_df[\"acc_x\"].min()), \n",
    "                                 (end-start),\n",
    "                                 labeled_df[\"acc_x\"].max()-labeled_df[\"acc_x\"].min(),\n",
    "                                 color = c, alpha = 0.4)\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "        custom_lines = []\n",
    "\n",
    "        for c in colors:\n",
    "\n",
    "            custom_lines.append(Line2D([0], [0], color=colors[c], lw=4, alpha= 0.7))\n",
    "\n",
    "        ax.legend(custom_lines, [activity[x] for x in colors],\n",
    "                 loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "                  fancybox=True, shadow=True, ncol=5)\n",
    "\n",
    "        ax.set_xlabel(\"time $[s]$\")\n",
    "        ax.set_ylabel(\"Amplitude\")\n",
    "        ax.set_title(\"Original Data\")\n",
    "        ax.grid()\n",
    "    \n",
    "    if save:\n",
    "        \n",
    "        plt.savefig(save_as)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:36:15.849282Z",
     "start_time": "2020-06-02T15:35:58.510203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read Data\n",
      "********************\n",
      "Filter Data\n",
      "********************\n",
      "Create Blocks\n",
      "********************\n",
      "Aggregate Data\n",
      "********************\n",
      "Load Model\n",
      "********************\n",
      "Label Data with the predictions\n",
      "********************\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 222 features, but this SimpleImputer is expecting 138 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-622-f7135d6c34d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Label Data with the predictions\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'*'\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mlabeled_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_original\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-617-67923c215bb4>\u001b[0m in \u001b[0;36mclassify\u001b[1;34m(df, model)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mesza\\.virtualenvs\\human-activity-recognition-7vqxol0e\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mesza\\.virtualenvs\\human-activity-recognition-7vqxol0e\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mesza\\.virtualenvs\\human-activity-recognition-7vqxol0e\\lib\\site-packages\\sklearn\\impute\\_base.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_fit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m         \u001b[0mX_indicator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform_indicator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mesza\\.virtualenvs\\human-activity-recognition-7vqxol0e\\lib\\site-packages\\sklearn\\impute\\_base.py\u001b[0m in \u001b[0;36m_validate_input\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    249\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mnew_ve\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[0m_check_inputs_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mesza\\.virtualenvs\\human-activity-recognition-7vqxol0e\\lib\\site-packages\\sklearn\\impute\\_base.py\u001b[0m in \u001b[0;36m_validate_input\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    242\u001b[0m                                     \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m                                     \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m                                     copy=self.copy)\n\u001b[0m\u001b[0;32m    245\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mve\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m\"could not convert\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mve\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mesza\\.virtualenvs\\human-activity-recognition-7vqxol0e\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ensure_2d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mesza\\.virtualenvs\\human-activity-recognition-7vqxol0e\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    378\u001b[0m                     \u001b[1;34m'X has {} features, but this {} is expecting {} features '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m                     'as input.'.format(n_features, self.__class__.__name__,\n\u001b[1;32m--> 380\u001b[1;33m                                        self.n_features_in_)\n\u001b[0m\u001b[0;32m    381\u001b[0m                 )\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 222 features, but this SimpleImputer is expecting 138 features as input."
     ]
    }
   ],
   "source": [
    "#experiment = 7\n",
    "\n",
    "print(\"Read Data\")\n",
    "print('*'*20)\n",
    "#df = read_test_data(experiment)\n",
    "\n",
    "df = read_real_data()\n",
    "\n",
    "print(\"Filter Data\")\n",
    "print('*'*20)\n",
    "df = remake_df(df)\n",
    "\n",
    "print(\"Create Blocks\")\n",
    "print('*'*20)\n",
    "df = create_block_df(df, 128)\n",
    "\n",
    "print(\"Aggregate Data\")\n",
    "print('*'*20)\n",
    "agg_df = create_aggregated(df)\n",
    "\n",
    "fft_df = do_fft(df)\n",
    "\n",
    "fft_agg_df = create_aggregated_freq(fft_df)\n",
    "\n",
    "clf_data = create_clf_data(agg_df,fft_agg_df)\n",
    "\n",
    "clf_data = preprocess_data(clf_data)\n",
    "\n",
    "print(\"Load Model\")\n",
    "print('*'*20)\n",
    "model = load_model(\"../models/har_model_v10.pkl\")\n",
    "\n",
    "print(\"Label Data with the predictions\")\n",
    "print('*'*20)\n",
    "labels = classify(clf_data,model)\n",
    "\n",
    "labeled_df = label_original(df,labels,model)\n",
    "\n",
    "labeled_agg_df = label_agg_df(agg_df,labels)\n",
    "\n",
    "print(\"Plot Data\")\n",
    "print('*'*20)\n",
    "plot_activity(labeled_df,labeled_agg_df, experiment=False, experiment_n = experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
